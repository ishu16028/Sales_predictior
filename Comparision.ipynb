{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load the data\n",
    "# Assuming the data is already loaded\n",
    "df = pd.read_csv(\"1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Feature engineering - Add year and week of the year columns\n",
    "df['transaction_date'] = pd.to_datetime(df['transaction_date'])\n",
    "df['week_of_year'] = df['transaction_date'].dt.isocalendar().week\n",
    "df['year'] = df['transaction_date'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Function to aggregate sales data weekly\n",
    "def aggregate_weekly_sales(df_product):\n",
    "    weekly_sales = df_product.groupby(['year', 'week_of_year']).agg({'quantity': 'sum'}).reset_index()\n",
    "    weekly_sales['date'] = pd.to_datetime(weekly_sales['year'].astype(str) + '-' + weekly_sales['week_of_year'].astype(str) + '-1', format='%Y-%W-%w')\n",
    "    weekly_sales.set_index('date', inplace=True)\n",
    "    \n",
    "    # Exogenous variables: Here, we'll just use 'discount_applied' and 'product_stock' as features for simplicity.\n",
    "    exogenous = df_product.groupby(['year', 'week_of_year']).agg({'discount_applied': 'mean', 'product_stock': 'mean'}).reset_index()\n",
    "    exogenous['date'] = pd.to_datetime(exogenous['year'].astype(str) + '-' + exogenous['week_of_year'].astype(str) + '-1', format='%Y-%W-%w')\n",
    "    exogenous.set_index('date', inplace=True)\n",
    "    \n",
    "    return weekly_sales['quantity'], exogenous[['discount_applied', 'product_stock']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Feature engineering and preprocessing\n",
    "def feature_engineering_and_preprocessing(df_product):\n",
    "    df_product['week_of_year'] = df_product['transaction_date'].dt.isocalendar().week\n",
    "    df_product['year'] = df_product['transaction_date'].dt.year\n",
    "    return df_product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the SARIMAX model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "# Function to train the SARIMAX model\n",
    "# Function to train the SARIMAX model\n",
    "def train_sarimax_model(df, product_id, order=(1, 1, 1), seasonal_order=(1, 1, 1, 52), forecast_steps=13):\n",
    "    # Filter the data for the specific product_id\n",
    "    df_product = df[df['product_id'] == product_id]\n",
    "    if df_product.empty:\n",
    "        raise ValueError(f\"No data found for product ID {product_id}\")\n",
    "    \n",
    "    # Feature engineering and preprocessing\n",
    "    df_product = feature_engineering_and_preprocessing(df_product)\n",
    "    \n",
    "    # Aggregate the sales data to weekly sales\n",
    "    weekly_sales, exogenous_weekly = aggregate_weekly_sales(df_product)\n",
    "    \n",
    "    # Check if we have enough data to train the model\n",
    "    if len(weekly_sales) < forecast_steps or len(exogenous_weekly) < forecast_steps:\n",
    "        raise ValueError(f\"Not enough data to forecast. Required: {forecast_steps}, Available Sales: {len(weekly_sales)}, Available Exogenous: {len(exogenous_weekly)}\")\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    train_size = int(len(weekly_sales) * 0.8)  # 80% train, 20% test\n",
    "    train_sales, test_sales = weekly_sales[:train_size], weekly_sales[train_size:]\n",
    "    train_exog, test_exog = exogenous_weekly[:train_size], exogenous_weekly[train_size:]\n",
    "\n",
    "    # Adjust the forecast_steps if not enough test data is available\n",
    "    if len(test_exog) < forecast_steps:\n",
    "        forecast_steps = len(test_exog)  # Use available exogenous data length\n",
    "\n",
    "    # Ensure test_exog has the correct shape\n",
    "    if len(test_exog) < forecast_steps:\n",
    "        raise ValueError(f\"Not enough exogenous data for forecasting. Required: {forecast_steps}, Available: {len(test_exog)}\")\n",
    "    \n",
    "    # Train the SARIMAX model on the training data\n",
    "    model = SARIMAX(train_sales, exog=train_exog, order=order, seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    return model_fit, test_sales, test_exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to forecast and evaluate the model\n",
    "def forecast_and_evaluate(model_fit, test_sales, test_exog, product_id, forecast_steps=13):\n",
    "    # Adjust forecast_steps if not enough exogenous data is available\n",
    "    if len(test_exog) < forecast_steps:\n",
    "        forecast_steps = len(test_exog)  # Use available exogenous data length\n",
    "    \n",
    "    # Ensure test_exog has the correct shape\n",
    "    if len(test_exog) < forecast_steps:\n",
    "        raise ValueError(f\"Not enough exogenous data for forecasting. Required: {forecast_steps}, Available: {len(test_exog)}\")\n",
    "    \n",
    "    # Generate forecast\n",
    "    forecast = model_fit.forecast(steps=forecast_steps, exog=test_exog[-forecast_steps:])  # Use the last forecast_steps rows\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    mae = mean_absolute_error(test_sales[:forecast_steps], forecast)\n",
    "    rmse = np.sqrt(mean_squared_error(test_sales[:forecast_steps], forecast))\n",
    "    mape = np.mean(np.abs((test_sales[:forecast_steps] - forecast) / test_sales[:forecast_steps])) * 100\n",
    "    \n",
    "    # Plotting the historical and forecasted sales\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(test_sales.index, test_sales, label='Actual Sales', marker='o')\n",
    "    plt.plot(test_sales.index[:forecast_steps], forecast, color='red', label='Forecasted Sales', marker='x')\n",
    "    plt.title(f\"Sales Forecast vs Actual for Product ID: {product_id}\")  # Added product ID to title\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Quantity Sold\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"MAE: {mae}, RMSE: {rmse}, MAPE: {mape}%\")\n",
    "    \n",
    "    return forecast, {\"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = 9459\n",
    "model_fit, test_sales, test_exog = train_sarimax_model(df, product_id)\n",
    "forecast, metrics = forecast_and_evaluate(model_fit, test_sales, test_exog, product_id, forecast_steps=13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
